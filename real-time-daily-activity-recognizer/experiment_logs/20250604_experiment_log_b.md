### ğŸ§ª Experiment Log â€“ 2025/06/04  
**ğŸ“‚ Project**: real-time-daily-activity-recognizer  
**ğŸ§ª Experiment**: CNN with Grayscale Input  
**ğŸ¯ Purpose**: Evaluate model performance with grayscale-converted input  
**ğŸ–¼ï¸ Plot Saved To**:  
`C:\Users\ghwns\HJ_git\CV-Projects\real-time-daily-activity-recognizer\figures\gray_experiment.png`

---

#### âœ… Experiment Details
- **Input Format**: Grayscale images (1 channel)
- **Model**: Simple CNN (Conv + MaxPooling + Dense layers)
- **Epochs**: 20  
- **Batch Size**: 128  
- **Optimizer**: Adam (`lr=0.0001`)  
- **Loss Function**: Categorical Crossentropy  
- **Metric**: Accuracy

---

#### ğŸ“Š Results Summary
- **Best Validation Accuracy**: `0.5330` at Epoch 19  
- **Overfitting**: âŒ No clear sign of overfitting (train/val gap moderate)  
- **Underfitting**: âœ… Likely underfitting  
  - Training accuracy plateaued at ~0.60  
  - Grayscale input may have reduced class-distinguishing features

---

#### ğŸ” Key Takeaways
- Grayscale input did **not** improve performance  
- Model may lack capacity to learn from limited grayscale info  
- Using RGB may retain more discriminative features

---

#### ğŸ”œ Next Steps
ï¬ Revert to RGB input to recover lost color information  
ï¬ Increase model depth / filter count (e.g., add more Conv layers, double filters)  
ï¬ Try transfer learning with MobileNet or similar architectures  
ï¬ Apply stronger data augmentation  
ï¬ Consider L2 regularization or Dropout to improve generalization
