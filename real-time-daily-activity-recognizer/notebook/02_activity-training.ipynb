{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb01b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3001 images belonging to 8 classes.\n",
      "Found 743 images belonging to 8 classes.\n",
      "Epoch 1/25\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 2.38825, saving model to mobilenetv2_finetune_augmented.keras\n",
      "47/47 - 67s - 1s/step - accuracy: 0.1539 - loss: 2.3640 - val_accuracy: 0.1884 - val_loss: 2.3882 - learning_rate: 1.0000e-05\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 2: val_loss improved from 2.38825 to 2.16710, saving model to mobilenetv2_finetune_augmented.keras\n",
      "47/47 - 48s - 1s/step - accuracy: 0.2299 - loss: 2.0950 - val_accuracy: 0.2436 - val_loss: 2.1671 - learning_rate: 1.0000e-05\n",
      "Epoch 3/25\n"
     ]
    }
   ],
   "source": [
    "# üìÖ 2025/06/06 - MobileNetV2 Fine-Tuning + Augmentation Í∞ïÌôî + ÏãúÍ∞ÅÌôî Ï∂úÎ†•ÍπåÏßÄ\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú\n",
    "data_dir = r\"C:\\Users\\ghwns\\HJ_git\\CV-Projects\\real-time-daily-activity-recognizer\\images\"\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ï (Í∞ïÌôî Î≤ÑÏ†Ñ)\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=10,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(128, 128),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(128, 128),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=64,\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# MobileNetV2 Î°úÎìú Î∞è fine-tuning\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(train_gen.num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(learning_rate=1e-5)\n",
    "\n",
    "# ÏΩúÎ∞±\n",
    "checkpoint_path = \"mobilenetv2_finetune_augmented.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, verbose=1)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Ïª¥ÌååÏùº\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ÌïôÏäµ\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=25,\n",
    "    callbacks=[checkpointer, lr_reducer, early_stopper],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî (Ï†ÄÏû• + ÌôîÎ©¥ Ï∂úÎ†•)\n",
    "fig_path = r\"C:\\Users\\ghwns\\HJ_git\\CV-Projects\\real-time-daily-activity-recognizer\\figures\\exp_20250606_finetune_mobilenet_augboost.png\"\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Fine-tuned MobileNetV2 + Strong Augmentation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_path)\n",
    "plt.show()  # Ï∂îÍ∞ÄÎêú Î∂ÄÎ∂Ñ: ÌôîÎ©¥ Ï∂úÎ†•\n",
    "\n",
    "# Î≤†Ïä§Ìä∏ Ïä§ÏΩîÏñ¥ Ï∂úÎ†•\n",
    "val_acc = history.history['val_accuracy']\n",
    "best_epoch = np.argmax(val_acc) + 1\n",
    "best_val = val_acc[best_epoch - 1]\n",
    "print(f\"‚úÖ Best val_acc: {best_val:.4f} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4bb120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
