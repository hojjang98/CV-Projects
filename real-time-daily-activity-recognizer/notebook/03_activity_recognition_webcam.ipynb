{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c781904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Webcam opened. Press 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¸ Real-Time Activity Recognition using EfficientNetB0\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# === Configuration ===\n",
    "model_path = \"efficientnetb0_baseline.keras\"  # Trained model file\n",
    "image_size = (160, 160)                       # Input size for the model\n",
    "class_dir = r\"C:\\Users\\ghwns\\HJ_git\\CV-Projects\\real-time-daily-activity-recognizer\\images\"\n",
    "label_list = sorted(os.listdir(class_dir))    # Class names inferred from directory names\n",
    "\n",
    "# === Load Pretrained Model ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Initialize Webcam ===\n",
    "cap = cv2.VideoCapture(0)  # 0 = default webcam\n",
    "\n",
    "if not cap.isOpened():\n",
    "    exit(\"Failed to open webcam.\")\n",
    "\n",
    "# === Real-Time Inference Loop ===\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize and preprocess frame\n",
    "    img = cv2.resize(frame, image_size)\n",
    "    img_array = np.expand_dims(img.astype(np.float32), axis=0)\n",
    "    img_preprocessed = preprocess_input(img_array)\n",
    "\n",
    "    # Predict activity\n",
    "    preds = model.predict(img_preprocessed, verbose=0)\n",
    "    pred_class = np.argmax(preds[0])\n",
    "    pred_label = label_list[pred_class]\n",
    "    confidence = preds[0][pred_class]\n",
    "\n",
    "    # Draw prediction label on frame\n",
    "    text = f\"{pred_label} ({confidence * 100:.1f}%)\"\n",
    "    cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Real-Time Activity Recognition\", frame)\n",
    "\n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# === Cleanup Resources ===\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fedb3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
