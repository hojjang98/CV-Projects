{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "H4yowB7VWMeJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N9cKGfItMxCh"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Data"
      ],
      "metadata": {
        "id": "LPQY7AGdWQTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000]\n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]"
      ],
      "metadata": {
        "id": "VAIdGD5VM50T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e7a82c3-6d13-4b7a-ecd2-4c1e4f9ace66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print('x_valid shape:', x_valid.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPhDxO0GWrCj",
        "outputId": "ed1935d2-2c35-4de7-c2c3-c8e56a7a72ba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (45000, 32, 32, 3)\n",
            "x_valid shape: (5000, 32, 32, 3)\n",
            "x_test shape: (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pixel Normaliztion"
      ],
      "metadata": {
        "id": "O5aDHaSDW3vI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(x_train, axis = (0, 1 ,2, 3))\n",
        "std = np.std(x_train, axis = (0, 1, 2, 3))\n",
        "x_train = (x_train - mean) / (std + 1e-7)\n",
        "x_valid = (x_valid - mean) / (std + 1e-7)\n",
        "x_test = (x_test - mean) / (std + 1e-7)"
      ],
      "metadata": {
        "id": "OnVS3OB_NGL6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Hot Encoding"
      ],
      "metadata": {
        "id": "LtnOfpnsXGIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "HvTp8LwPNSa8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augumentation"
      ],
      "metadata": {
        "id": "8MgxsruFXPeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 15,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = False\n",
        ")\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "JtCJ0wbzNfxD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Model(6CONV + 1FC)"
      ],
      "metadata": {
        "id": "0b8TWXZzXkPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_hidden_units = 32\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "\n",
        "# CONV1\n",
        "input_shape = x_train.shape[1:]\n",
        "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                 input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV2\n",
        "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# POOL + Dropout\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# CONV3\n",
        "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV4\n",
        "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# POOL + Dropout\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# CONV5\n",
        "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# POOL + Dropout\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# CONV6\n",
        "model.add(Conv2D(base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# POOL + Dropout\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# FC7\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "WfQOQN0aFOXt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45995902-b905-4b08-ffbd-1570ae8a0ec5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,194\u001b[0m (192.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,194</span> (192.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,810\u001b[0m (190.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,810</span> (190.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 125\n",
        "\n",
        "checkpointer = ModelCheckpoint(\n",
        "    filepath='model.100epochs.keras',\n",
        "    verbose=1,\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    callbacks=[checkpointer],\n",
        "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=2,\n",
        "    validation_data=(x_valid, y_valid)\n",
        ")\n"
      ],
      "metadata": {
        "id": "CJ4LjASmFZhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dbb93ed-b22e-4b97-b16d-56b2130b109c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.17066, saving model to model.100epochs.keras\n",
            "351/351 - 173s - 493ms/step - accuracy: 0.1610 - loss: 3.1149 - val_accuracy: 0.1914 - val_loss: 2.1707\n",
            "Epoch 2/125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_loss improved from 2.17066 to 2.16754, saving model to model.100epochs.keras\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.2656 - loss: 2.5677 - val_accuracy: 0.1922 - val_loss: 2.1675\n",
            "Epoch 3/125\n",
            "\n",
            "Epoch 3: val_loss improved from 2.16754 to 1.75694, saving model to model.100epochs.keras\n",
            "351/351 - 204s - 582ms/step - accuracy: 0.2380 - loss: 2.3839 - val_accuracy: 0.3454 - val_loss: 1.7569\n",
            "Epoch 4/125\n",
            "\n",
            "Epoch 4: val_loss did not improve from 1.75694\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.2891 - loss: 2.1744 - val_accuracy: 0.3450 - val_loss: 1.7576\n",
            "Epoch 5/125\n",
            "\n",
            "Epoch 5: val_loss improved from 1.75694 to 1.65482, saving model to model.100epochs.keras\n",
            "351/351 - 252s - 719ms/step - accuracy: 0.2836 - loss: 2.1223 - val_accuracy: 0.4004 - val_loss: 1.6548\n",
            "Epoch 6/125\n",
            "\n",
            "Epoch 6: val_loss improved from 1.65482 to 1.65415, saving model to model.100epochs.keras\n",
            "351/351 - 5s - 15ms/step - accuracy: 0.3281 - loss: 2.0924 - val_accuracy: 0.4006 - val_loss: 1.6541\n",
            "Epoch 7/125\n",
            "\n",
            "Epoch 7: val_loss improved from 1.65415 to 1.59919, saving model to model.100epochs.keras\n",
            "351/351 - 205s - 583ms/step - accuracy: 0.3114 - loss: 1.9888 - val_accuracy: 0.4150 - val_loss: 1.5992\n",
            "Epoch 8/125\n",
            "\n",
            "Epoch 8: val_loss improved from 1.59919 to 1.59907, saving model to model.100epochs.keras\n",
            "351/351 - 11s - 31ms/step - accuracy: 0.3281 - loss: 1.8676 - val_accuracy: 0.4154 - val_loss: 1.5991\n",
            "Epoch 9/125\n",
            "\n",
            "Epoch 9: val_loss improved from 1.59907 to 1.56834, saving model to model.100epochs.keras\n",
            "351/351 - 195s - 555ms/step - accuracy: 0.3288 - loss: 1.8997 - val_accuracy: 0.4356 - val_loss: 1.5683\n",
            "Epoch 10/125\n",
            "\n",
            "Epoch 10: val_loss did not improve from 1.56834\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.3438 - loss: 1.7173 - val_accuracy: 0.4366 - val_loss: 1.5688\n",
            "Epoch 11/125\n",
            "\n",
            "Epoch 11: val_loss improved from 1.56834 to 1.54210, saving model to model.100epochs.keras\n",
            "351/351 - 145s - 413ms/step - accuracy: 0.3499 - loss: 1.8181 - val_accuracy: 0.4340 - val_loss: 1.5421\n",
            "Epoch 12/125\n",
            "\n",
            "Epoch 12: val_loss improved from 1.54210 to 1.54003, saving model to model.100epochs.keras\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.3516 - loss: 1.8288 - val_accuracy: 0.4338 - val_loss: 1.5400\n",
            "Epoch 13/125\n",
            "\n",
            "Epoch 13: val_loss improved from 1.54003 to 1.53739, saving model to model.100epochs.keras\n",
            "351/351 - 199s - 566ms/step - accuracy: 0.3735 - loss: 1.7483 - val_accuracy: 0.4376 - val_loss: 1.5374\n",
            "Epoch 14/125\n",
            "\n",
            "Epoch 14: val_loss improved from 1.53739 to 1.53720, saving model to model.100epochs.keras\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.4219 - loss: 1.6139 - val_accuracy: 0.4372 - val_loss: 1.5372\n",
            "Epoch 15/125\n",
            "\n",
            "Epoch 15: val_loss improved from 1.53720 to 1.51272, saving model to model.100epochs.keras\n",
            "351/351 - 143s - 407ms/step - accuracy: 0.3892 - loss: 1.6955 - val_accuracy: 0.4470 - val_loss: 1.5127\n",
            "Epoch 16/125\n",
            "\n",
            "Epoch 16: val_loss improved from 1.51272 to 1.50970, saving model to model.100epochs.keras\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.4062 - loss: 1.6795 - val_accuracy: 0.4480 - val_loss: 1.5097\n",
            "Epoch 17/125\n",
            "\n",
            "Epoch 17: val_loss improved from 1.50970 to 1.46865, saving model to model.100epochs.keras\n",
            "351/351 - 148s - 422ms/step - accuracy: 0.4042 - loss: 1.6468 - val_accuracy: 0.4590 - val_loss: 1.4687\n",
            "Epoch 18/125\n",
            "\n",
            "Epoch 18: val_loss did not improve from 1.46865\n",
            "351/351 - 5s - 16ms/step - accuracy: 0.4062 - loss: 1.5949 - val_accuracy: 0.4600 - val_loss: 1.4694\n",
            "Epoch 19/125\n",
            "\n",
            "Epoch 19: val_loss did not improve from 1.46865\n",
            "351/351 - 155s - 442ms/step - accuracy: 0.4207 - loss: 1.5991 - val_accuracy: 0.4548 - val_loss: 1.4808\n",
            "Epoch 20/125\n",
            "\n",
            "Epoch 20: val_loss did not improve from 1.46865\n",
            "351/351 - 5s - 16ms/step - accuracy: 0.4688 - loss: 1.5929 - val_accuracy: 0.4550 - val_loss: 1.4845\n",
            "Epoch 21/125\n",
            "\n",
            "Epoch 21: val_loss did not improve from 1.46865\n",
            "351/351 - 194s - 552ms/step - accuracy: 0.4330 - loss: 1.5604 - val_accuracy: 0.4468 - val_loss: 1.5157\n",
            "Epoch 22/125\n",
            "\n",
            "Epoch 22: val_loss did not improve from 1.46865\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.4531 - loss: 1.5470 - val_accuracy: 0.4480 - val_loss: 1.5141\n",
            "Epoch 23/125\n",
            "\n",
            "Epoch 23: val_loss did not improve from 1.46865\n",
            "351/351 - 147s - 419ms/step - accuracy: 0.4536 - loss: 1.5141 - val_accuracy: 0.4514 - val_loss: 1.4798\n",
            "Epoch 24/125\n",
            "\n",
            "Epoch 24: val_loss did not improve from 1.46865\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.3516 - loss: 1.7105 - val_accuracy: 0.4512 - val_loss: 1.4785\n",
            "Epoch 25/125\n",
            "\n",
            "Epoch 25: val_loss improved from 1.46865 to 1.45080, saving model to model.100epochs.keras\n",
            "351/351 - 150s - 429ms/step - accuracy: 0.4633 - loss: 1.4853 - val_accuracy: 0.4712 - val_loss: 1.4508\n",
            "Epoch 26/125\n",
            "\n",
            "Epoch 26: val_loss improved from 1.45080 to 1.44381, saving model to model.100epochs.keras\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.5000 - loss: 1.4445 - val_accuracy: 0.4720 - val_loss: 1.4438\n",
            "Epoch 27/125\n",
            "\n",
            "Epoch 27: val_loss did not improve from 1.44381\n",
            "351/351 - 157s - 449ms/step - accuracy: 0.4769 - loss: 1.4446 - val_accuracy: 0.4642 - val_loss: 1.4734\n",
            "Epoch 28/125\n",
            "\n",
            "Epoch 28: val_loss did not improve from 1.44381\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.4141 - loss: 1.4927 - val_accuracy: 0.4654 - val_loss: 1.4719\n",
            "Epoch 29/125\n",
            "\n",
            "Epoch 29: val_loss did not improve from 1.44381\n",
            "351/351 - 155s - 442ms/step - accuracy: 0.4888 - loss: 1.4159 - val_accuracy: 0.4790 - val_loss: 1.4519\n",
            "Epoch 30/125\n",
            "\n",
            "Epoch 30: val_loss did not improve from 1.44381\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.5391 - loss: 1.3898 - val_accuracy: 0.4796 - val_loss: 1.4497\n",
            "Epoch 31/125\n",
            "\n",
            "Epoch 31: val_loss improved from 1.44381 to 1.42280, saving model to model.100epochs.keras\n",
            "351/351 - 150s - 427ms/step - accuracy: 0.5012 - loss: 1.3822 - val_accuracy: 0.4846 - val_loss: 1.4228\n",
            "Epoch 32/125\n",
            "\n",
            "Epoch 32: val_loss improved from 1.42280 to 1.42263, saving model to model.100epochs.keras\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.5078 - loss: 1.4380 - val_accuracy: 0.4848 - val_loss: 1.4226\n",
            "Epoch 33/125\n",
            "\n",
            "Epoch 33: val_loss improved from 1.42263 to 1.36825, saving model to model.100epochs.keras\n",
            "351/351 - 150s - 427ms/step - accuracy: 0.5082 - loss: 1.3616 - val_accuracy: 0.5110 - val_loss: 1.3682\n",
            "Epoch 34/125\n",
            "\n",
            "Epoch 34: val_loss did not improve from 1.36825\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.4844 - loss: 1.4011 - val_accuracy: 0.5106 - val_loss: 1.3709\n",
            "Epoch 35/125\n",
            "\n",
            "Epoch 35: val_loss did not improve from 1.36825\n",
            "351/351 - 197s - 561ms/step - accuracy: 0.5199 - loss: 1.3333 - val_accuracy: 0.5082 - val_loss: 1.3688\n",
            "Epoch 36/125\n",
            "\n",
            "Epoch 36: val_loss improved from 1.36825 to 1.36772, saving model to model.100epochs.keras\n",
            "351/351 - 4s - 12ms/step - accuracy: 0.5078 - loss: 1.3749 - val_accuracy: 0.5094 - val_loss: 1.3677\n",
            "Epoch 37/125\n",
            "\n",
            "Epoch 37: val_loss improved from 1.36772 to 1.35214, saving model to model.100epochs.keras\n",
            "351/351 - 148s - 423ms/step - accuracy: 0.5324 - loss: 1.3099 - val_accuracy: 0.5192 - val_loss: 1.3521\n",
            "Epoch 38/125\n",
            "\n",
            "Epoch 38: val_loss did not improve from 1.35214\n",
            "351/351 - 4s - 12ms/step - accuracy: 0.5156 - loss: 1.3378 - val_accuracy: 0.5200 - val_loss: 1.3532\n",
            "Epoch 39/125\n",
            "\n",
            "Epoch 39: val_loss improved from 1.35214 to 1.30808, saving model to model.100epochs.keras\n",
            "351/351 - 203s - 577ms/step - accuracy: 0.5407 - loss: 1.2871 - val_accuracy: 0.5316 - val_loss: 1.3081\n",
            "Epoch 40/125\n",
            "\n",
            "Epoch 40: val_loss did not improve from 1.30808\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.5156 - loss: 1.2574 - val_accuracy: 0.5300 - val_loss: 1.3084\n",
            "Epoch 41/125\n",
            "\n",
            "Epoch 41: val_loss improved from 1.30808 to 1.30166, saving model to model.100epochs.keras\n",
            "351/351 - 156s - 446ms/step - accuracy: 0.5503 - loss: 1.2637 - val_accuracy: 0.5344 - val_loss: 1.3017\n",
            "Epoch 42/125\n",
            "\n",
            "Epoch 42: val_loss did not improve from 1.30166\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6094 - loss: 1.2213 - val_accuracy: 0.5348 - val_loss: 1.3023\n",
            "Epoch 43/125\n",
            "\n",
            "Epoch 43: val_loss did not improve from 1.30166\n",
            "351/351 - 185s - 528ms/step - accuracy: 0.5581 - loss: 1.2446 - val_accuracy: 0.5298 - val_loss: 1.3212\n",
            "Epoch 44/125\n",
            "\n",
            "Epoch 44: val_loss did not improve from 1.30166\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.5000 - loss: 1.3991 - val_accuracy: 0.5290 - val_loss: 1.3270\n",
            "Epoch 45/125\n",
            "\n",
            "Epoch 45: val_loss improved from 1.30166 to 1.27189, saving model to model.100epochs.keras\n",
            "351/351 - 147s - 419ms/step - accuracy: 0.5642 - loss: 1.2274 - val_accuracy: 0.5444 - val_loss: 1.2719\n",
            "Epoch 46/125\n",
            "\n",
            "Epoch 46: val_loss improved from 1.27189 to 1.26573, saving model to model.100epochs.keras\n",
            "351/351 - 4s - 12ms/step - accuracy: 0.5781 - loss: 1.2130 - val_accuracy: 0.5462 - val_loss: 1.2657\n",
            "Epoch 47/125\n",
            "\n",
            "Epoch 47: val_loss improved from 1.26573 to 1.23967, saving model to model.100epochs.keras\n",
            "351/351 - 147s - 419ms/step - accuracy: 0.5688 - loss: 1.2151 - val_accuracy: 0.5564 - val_loss: 1.2397\n",
            "Epoch 48/125\n",
            "\n",
            "Epoch 48: val_loss improved from 1.23967 to 1.23851, saving model to model.100epochs.keras\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6797 - loss: 0.9872 - val_accuracy: 0.5562 - val_loss: 1.2385\n",
            "Epoch 49/125\n",
            "\n",
            "Epoch 49: val_loss did not improve from 1.23851\n",
            "351/351 - 203s - 578ms/step - accuracy: 0.5781 - loss: 1.1971 - val_accuracy: 0.5638 - val_loss: 1.2478\n",
            "Epoch 50/125\n",
            "\n",
            "Epoch 50: val_loss did not improve from 1.23851\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6016 - loss: 1.1694 - val_accuracy: 0.5636 - val_loss: 1.2493\n",
            "Epoch 51/125\n",
            "\n",
            "Epoch 51: val_loss improved from 1.23851 to 1.23162, saving model to model.100epochs.keras\n",
            "351/351 - 192s - 547ms/step - accuracy: 0.5788 - loss: 1.1816 - val_accuracy: 0.5660 - val_loss: 1.2316\n",
            "Epoch 52/125\n",
            "\n",
            "Epoch 52: val_loss did not improve from 1.23162\n",
            "351/351 - 5s - 16ms/step - accuracy: 0.5312 - loss: 1.1944 - val_accuracy: 0.5664 - val_loss: 1.2352\n",
            "Epoch 53/125\n",
            "\n",
            "Epoch 53: val_loss improved from 1.23162 to 1.20476, saving model to model.100epochs.keras\n",
            "351/351 - 199s - 566ms/step - accuracy: 0.5863 - loss: 1.1726 - val_accuracy: 0.5708 - val_loss: 1.2048\n",
            "Epoch 54/125\n",
            "\n",
            "Epoch 54: val_loss did not improve from 1.20476\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.5625 - loss: 1.2849 - val_accuracy: 0.5694 - val_loss: 1.2079\n",
            "Epoch 55/125\n",
            "\n",
            "Epoch 55: val_loss improved from 1.20476 to 1.18464, saving model to model.100epochs.keras\n",
            "351/351 - 204s - 580ms/step - accuracy: 0.5903 - loss: 1.1568 - val_accuracy: 0.5806 - val_loss: 1.1846\n",
            "Epoch 56/125\n",
            "\n",
            "Epoch 56: val_loss improved from 1.18464 to 1.18336, saving model to model.100epochs.keras\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6016 - loss: 1.0811 - val_accuracy: 0.5804 - val_loss: 1.1834\n",
            "Epoch 57/125\n",
            "\n",
            "Epoch 57: val_loss improved from 1.18336 to 1.17869, saving model to model.100epochs.keras\n",
            "351/351 - 154s - 438ms/step - accuracy: 0.5954 - loss: 1.1458 - val_accuracy: 0.5780 - val_loss: 1.1787\n",
            "Epoch 58/125\n",
            "\n",
            "Epoch 58: val_loss did not improve from 1.17869\n",
            "351/351 - 4s - 13ms/step - accuracy: 0.6016 - loss: 1.1739 - val_accuracy: 0.5784 - val_loss: 1.1812\n",
            "Epoch 59/125\n",
            "\n",
            "Epoch 59: val_loss did not improve from 1.17869\n",
            "351/351 - 200s - 569ms/step - accuracy: 0.5999 - loss: 1.1370 - val_accuracy: 0.5782 - val_loss: 1.1905\n",
            "Epoch 60/125\n",
            "\n",
            "Epoch 60: val_loss did not improve from 1.17869\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.6484 - loss: 1.0427 - val_accuracy: 0.5794 - val_loss: 1.1870\n",
            "Epoch 61/125\n",
            "\n",
            "Epoch 61: val_loss improved from 1.17869 to 1.14940, saving model to model.100epochs.keras\n",
            "351/351 - 196s - 558ms/step - accuracy: 0.6018 - loss: 1.1230 - val_accuracy: 0.5940 - val_loss: 1.1494\n",
            "Epoch 62/125\n",
            "\n",
            "Epoch 62: val_loss improved from 1.14940 to 1.14731, saving model to model.100epochs.keras\n",
            "351/351 - 5s - 13ms/step - accuracy: 0.5703 - loss: 1.2062 - val_accuracy: 0.5948 - val_loss: 1.1473\n",
            "Epoch 63/125\n",
            "\n",
            "Epoch 63: val_loss did not improve from 1.14731\n",
            "351/351 - 150s - 426ms/step - accuracy: 0.6090 - loss: 1.1109 - val_accuracy: 0.5980 - val_loss: 1.1509\n",
            "Epoch 64/125\n",
            "\n",
            "Epoch 64: val_loss did not improve from 1.14731\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.5859 - loss: 1.2208 - val_accuracy: 0.5980 - val_loss: 1.1553\n",
            "Epoch 65/125\n",
            "\n",
            "Epoch 65: val_loss improved from 1.14731 to 1.13170, saving model to model.100epochs.keras\n",
            "351/351 - 203s - 579ms/step - accuracy: 0.6127 - loss: 1.1022 - val_accuracy: 0.5940 - val_loss: 1.1317\n",
            "Epoch 66/125\n",
            "\n",
            "Epoch 66: val_loss did not improve from 1.13170\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6172 - loss: 1.0035 - val_accuracy: 0.5940 - val_loss: 1.1323\n",
            "Epoch 67/125\n",
            "\n",
            "Epoch 67: val_loss did not improve from 1.13170\n",
            "351/351 - 197s - 562ms/step - accuracy: 0.6132 - loss: 1.0957 - val_accuracy: 0.5888 - val_loss: 1.1543\n",
            "Epoch 68/125\n",
            "\n",
            "Epoch 68: val_loss did not improve from 1.13170\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6406 - loss: 1.0838 - val_accuracy: 0.5950 - val_loss: 1.1464\n",
            "Epoch 69/125\n",
            "\n",
            "Epoch 69: val_loss improved from 1.13170 to 1.11470, saving model to model.100epochs.keras\n",
            "351/351 - 159s - 452ms/step - accuracy: 0.6151 - loss: 1.0907 - val_accuracy: 0.6072 - val_loss: 1.1147\n",
            "Epoch 70/125\n",
            "\n",
            "Epoch 70: val_loss improved from 1.11470 to 1.11388, saving model to model.100epochs.keras\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6406 - loss: 0.9690 - val_accuracy: 0.6080 - val_loss: 1.1139\n",
            "Epoch 71/125\n",
            "\n",
            "Epoch 71: val_loss improved from 1.11388 to 1.06925, saving model to model.100epochs.keras\n",
            "351/351 - 163s - 464ms/step - accuracy: 0.6203 - loss: 1.0807 - val_accuracy: 0.6242 - val_loss: 1.0692\n",
            "Epoch 72/125\n",
            "\n",
            "Epoch 72: val_loss did not improve from 1.06925\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6328 - loss: 1.0532 - val_accuracy: 0.6230 - val_loss: 1.0707\n",
            "Epoch 73/125\n",
            "\n",
            "Epoch 73: val_loss did not improve from 1.06925\n",
            "351/351 - 154s - 439ms/step - accuracy: 0.6227 - loss: 1.0712 - val_accuracy: 0.6082 - val_loss: 1.0999\n",
            "Epoch 74/125\n",
            "\n",
            "Epoch 74: val_loss did not improve from 1.06925\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.6094 - loss: 1.1093 - val_accuracy: 0.6070 - val_loss: 1.1012\n",
            "Epoch 75/125\n",
            "\n",
            "Epoch 75: val_loss did not improve from 1.06925\n",
            "351/351 - 196s - 559ms/step - accuracy: 0.6307 - loss: 1.0587 - val_accuracy: 0.6074 - val_loss: 1.1053\n",
            "Epoch 76/125\n",
            "\n",
            "Epoch 76: val_loss did not improve from 1.06925\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.7109 - loss: 0.9893 - val_accuracy: 0.6072 - val_loss: 1.1055\n",
            "Epoch 77/125\n",
            "\n",
            "Epoch 77: val_loss did not improve from 1.06925\n",
            "351/351 - 151s - 429ms/step - accuracy: 0.6281 - loss: 1.0628 - val_accuracy: 0.6130 - val_loss: 1.0923\n",
            "Epoch 78/125\n",
            "\n",
            "Epoch 78: val_loss did not improve from 1.06925\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6172 - loss: 1.0220 - val_accuracy: 0.6116 - val_loss: 1.0943\n",
            "Epoch 79/125\n",
            "\n",
            "Epoch 79: val_loss improved from 1.06925 to 1.05836, saving model to model.100epochs.keras\n",
            "351/351 - 198s - 563ms/step - accuracy: 0.6334 - loss: 1.0488 - val_accuracy: 0.6312 - val_loss: 1.0584\n",
            "Epoch 80/125\n",
            "\n",
            "Epoch 80: val_loss improved from 1.05836 to 1.05768, saving model to model.100epochs.keras\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6797 - loss: 0.8110 - val_accuracy: 0.6306 - val_loss: 1.0577\n",
            "Epoch 81/125\n",
            "\n",
            "Epoch 81: val_loss did not improve from 1.05768\n",
            "351/351 - 194s - 552ms/step - accuracy: 0.6327 - loss: 1.0441 - val_accuracy: 0.6228 - val_loss: 1.0627\n",
            "Epoch 82/125\n",
            "\n",
            "Epoch 82: val_loss improved from 1.05768 to 1.05692, saving model to model.100epochs.keras\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6562 - loss: 1.0105 - val_accuracy: 0.6260 - val_loss: 1.0569\n",
            "Epoch 83/125\n",
            "\n",
            "Epoch 83: val_loss improved from 1.05692 to 1.03474, saving model to model.100epochs.keras\n",
            "351/351 - 150s - 426ms/step - accuracy: 0.6371 - loss: 1.0377 - val_accuracy: 0.6344 - val_loss: 1.0347\n",
            "Epoch 84/125\n",
            "\n",
            "Epoch 84: val_loss improved from 1.03474 to 1.03469, saving model to model.100epochs.keras\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6562 - loss: 1.0222 - val_accuracy: 0.6356 - val_loss: 1.0347\n",
            "Epoch 85/125\n",
            "\n",
            "Epoch 85: val_loss improved from 1.03469 to 1.01742, saving model to model.100epochs.keras\n",
            "351/351 - 204s - 581ms/step - accuracy: 0.6397 - loss: 1.0324 - val_accuracy: 0.6434 - val_loss: 1.0174\n",
            "Epoch 86/125\n",
            "\n",
            "Epoch 86: val_loss improved from 1.01742 to 1.01640, saving model to model.100epochs.keras\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.5781 - loss: 1.0958 - val_accuracy: 0.6440 - val_loss: 1.0164\n",
            "Epoch 87/125\n",
            "\n",
            "Epoch 87: val_loss improved from 1.01640 to 0.99792, saving model to model.100epochs.keras\n",
            "351/351 - 194s - 554ms/step - accuracy: 0.6418 - loss: 1.0284 - val_accuracy: 0.6538 - val_loss: 0.9979\n",
            "Epoch 88/125\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.99792\n",
            "351/351 - 5s - 16ms/step - accuracy: 0.6328 - loss: 1.0614 - val_accuracy: 0.6536 - val_loss: 0.9984\n",
            "Epoch 89/125\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.99792\n",
            "351/351 - 146s - 416ms/step - accuracy: 0.6439 - loss: 1.0177 - val_accuracy: 0.6388 - val_loss: 1.0343\n",
            "Epoch 90/125\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.99792\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.5469 - loss: 1.1707 - val_accuracy: 0.6382 - val_loss: 1.0373\n",
            "Epoch 91/125\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.99792\n",
            "351/351 - 150s - 427ms/step - accuracy: 0.6454 - loss: 1.0145 - val_accuracy: 0.6474 - val_loss: 1.0045\n",
            "Epoch 92/125\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.99792\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6172 - loss: 1.0836 - val_accuracy: 0.6472 - val_loss: 1.0027\n",
            "Epoch 93/125\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.99792\n",
            "351/351 - 152s - 432ms/step - accuracy: 0.6489 - loss: 1.0057 - val_accuracy: 0.6470 - val_loss: 1.0012\n",
            "Epoch 94/125\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.99792\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6875 - loss: 1.0620 - val_accuracy: 0.6462 - val_loss: 1.0034\n",
            "Epoch 95/125\n",
            "\n",
            "Epoch 95: val_loss improved from 0.99792 to 0.97048, saving model to model.100epochs.keras\n",
            "351/351 - 152s - 434ms/step - accuracy: 0.6504 - loss: 1.0069 - val_accuracy: 0.6612 - val_loss: 0.9705\n",
            "Epoch 96/125\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.97048\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.6719 - loss: 0.9867 - val_accuracy: 0.6594 - val_loss: 0.9715\n",
            "Epoch 97/125\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.97048\n",
            "351/351 - 146s - 416ms/step - accuracy: 0.6526 - loss: 0.9961 - val_accuracy: 0.6460 - val_loss: 0.9887\n",
            "Epoch 98/125\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.97048\n",
            "351/351 - 4s - 10ms/step - accuracy: 0.5938 - loss: 1.0600 - val_accuracy: 0.6476 - val_loss: 0.9882\n",
            "Epoch 99/125\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.97048\n",
            "351/351 - 202s - 576ms/step - accuracy: 0.6525 - loss: 0.9942 - val_accuracy: 0.6468 - val_loss: 1.0082\n",
            "Epoch 100/125\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.97048\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.6172 - loss: 1.0189 - val_accuracy: 0.6466 - val_loss: 1.0088\n",
            "Epoch 101/125\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.97048\n",
            "351/351 - 209s - 594ms/step - accuracy: 0.6549 - loss: 0.9834 - val_accuracy: 0.6558 - val_loss: 0.9875\n",
            "Epoch 102/125\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.97048\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.6484 - loss: 1.0271 - val_accuracy: 0.6564 - val_loss: 0.9853\n",
            "Epoch 103/125\n",
            "\n",
            "Epoch 103: val_loss improved from 0.97048 to 0.96292, saving model to model.100epochs.keras\n",
            "351/351 - 158s - 451ms/step - accuracy: 0.6550 - loss: 0.9851 - val_accuracy: 0.6644 - val_loss: 0.9629\n",
            "Epoch 104/125\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.96292\n",
            "351/351 - 4s - 13ms/step - accuracy: 0.6875 - loss: 0.8941 - val_accuracy: 0.6636 - val_loss: 0.9655\n",
            "Epoch 105/125\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.96292\n",
            "351/351 - 193s - 551ms/step - accuracy: 0.6574 - loss: 0.9776 - val_accuracy: 0.6448 - val_loss: 1.0025\n",
            "Epoch 106/125\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.96292\n",
            "351/351 - 4s - 12ms/step - accuracy: 0.6328 - loss: 1.1909 - val_accuracy: 0.6446 - val_loss: 1.0039\n",
            "Epoch 107/125\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.96292\n",
            "351/351 - 146s - 416ms/step - accuracy: 0.6611 - loss: 0.9707 - val_accuracy: 0.6524 - val_loss: 0.9777\n",
            "Epoch 108/125\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.96292\n",
            "351/351 - 4s - 12ms/step - accuracy: 0.6797 - loss: 0.9260 - val_accuracy: 0.6518 - val_loss: 0.9817\n",
            "Epoch 109/125\n",
            "\n",
            "Epoch 109: val_loss improved from 0.96292 to 0.94741, saving model to model.100epochs.keras\n",
            "351/351 - 151s - 431ms/step - accuracy: 0.6622 - loss: 0.9667 - val_accuracy: 0.6630 - val_loss: 0.9474\n",
            "Epoch 110/125\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.94741\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6484 - loss: 1.0251 - val_accuracy: 0.6624 - val_loss: 0.9494\n",
            "Epoch 111/125\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.94741\n",
            "351/351 - 202s - 574ms/step - accuracy: 0.6628 - loss: 0.9661 - val_accuracy: 0.6630 - val_loss: 0.9483\n",
            "Epoch 112/125\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.94741\n",
            "351/351 - 4s - 11ms/step - accuracy: 0.6875 - loss: 0.8495 - val_accuracy: 0.6632 - val_loss: 0.9487\n",
            "Epoch 113/125\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.94741\n",
            "351/351 - 198s - 564ms/step - accuracy: 0.6655 - loss: 0.9590 - val_accuracy: 0.6624 - val_loss: 0.9519\n",
            "Epoch 114/125\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.94741\n",
            "351/351 - 5s - 16ms/step - accuracy: 0.6797 - loss: 0.9363 - val_accuracy: 0.6634 - val_loss: 0.9513\n",
            "Epoch 115/125\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.94741\n",
            "351/351 - 151s - 431ms/step - accuracy: 0.6661 - loss: 0.9635 - val_accuracy: 0.6588 - val_loss: 0.9665\n",
            "Epoch 116/125\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.94741\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6328 - loss: 0.9764 - val_accuracy: 0.6590 - val_loss: 0.9677\n",
            "Epoch 117/125\n",
            "\n",
            "Epoch 117: val_loss improved from 0.94741 to 0.92855, saving model to model.100epochs.keras\n",
            "351/351 - 207s - 590ms/step - accuracy: 0.6695 - loss: 0.9578 - val_accuracy: 0.6704 - val_loss: 0.9285\n",
            "Epoch 118/125\n",
            "\n",
            "Epoch 118: val_loss improved from 0.92855 to 0.92781, saving model to model.100epochs.keras\n",
            "351/351 - 4s - 13ms/step - accuracy: 0.6562 - loss: 1.0051 - val_accuracy: 0.6694 - val_loss: 0.9278\n",
            "Epoch 119/125\n",
            "\n",
            "Epoch 119: val_loss improved from 0.92781 to 0.91955, saving model to model.100epochs.keras\n",
            "351/351 - 161s - 459ms/step - accuracy: 0.6709 - loss: 0.9503 - val_accuracy: 0.6728 - val_loss: 0.9196\n",
            "Epoch 120/125\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.91955\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.7188 - loss: 0.8960 - val_accuracy: 0.6726 - val_loss: 0.9205\n",
            "Epoch 121/125\n",
            "\n",
            "Epoch 121: val_loss improved from 0.91955 to 0.91073, saving model to model.100epochs.keras\n",
            "351/351 - 204s - 580ms/step - accuracy: 0.6707 - loss: 0.9419 - val_accuracy: 0.6804 - val_loss: 0.9107\n",
            "Epoch 122/125\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.91073\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.6172 - loss: 1.1909 - val_accuracy: 0.6792 - val_loss: 0.9118\n",
            "Epoch 123/125\n",
            "\n",
            "Epoch 123: val_loss improved from 0.91073 to 0.90204, saving model to model.100epochs.keras\n",
            "351/351 - 185s - 528ms/step - accuracy: 0.6729 - loss: 0.9389 - val_accuracy: 0.6830 - val_loss: 0.9020\n",
            "Epoch 124/125\n",
            "\n",
            "Epoch 124: val_loss improved from 0.90204 to 0.90125, saving model to model.100epochs.keras\n",
            "351/351 - 6s - 16ms/step - accuracy: 0.7266 - loss: 0.8410 - val_accuracy: 0.6818 - val_loss: 0.9012\n",
            "Epoch 125/125\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.90125\n",
            "351/351 - 165s - 470ms/step - accuracy: 0.6723 - loss: 0.9407 - val_accuracy: 0.6666 - val_loss: 0.9369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, batch_size = 128, verbose = 1)\n",
        "print('\\n Test result: %.3f loss: %.3f' % (scores[1]*100, scores[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8IvMDnRZxUK",
        "outputId": "c061697c-c839-4b42-889c-71ea53aaf505"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 83ms/step - accuracy: 0.6560 - loss: 0.9629\n",
            "\n",
            " Test result: 65.250 loss: 0.973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='train_acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "qOq-kMbVaQxo",
        "outputId": "3b5b0c06-cf35-4590-e8f5-9de1f3100ee6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pj80W3SHaY4A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}